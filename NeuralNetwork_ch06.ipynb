{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork-ch06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYcLdWUa3Weondm2fOwIGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ja-yu/AI/blob/main/NeuralNetwork_ch06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3psO0vJlXEkw",
        "outputId": "fe78c07a-db67-4d2a-bc08-244dd75f8af5"
      },
      "source": [
        "! git clone https://github.com/oreilly-japan/deep-learning-from-scratch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 446, done.\u001b[K\n",
            "remote: Total 446 (delta 0), reused 0 (delta 0), pack-reused 446\u001b[K\n",
            "Receiving objects: 100% (446/446), 5.52 MiB | 20.76 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEbqeUdHXYRM",
        "outputId": "64d6708c-2862-4f9f-e814-a3f7e74ae4e9"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdeep-learning-from-scratch\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyMCFhHxXh5w",
        "outputId": "ea9c3120-46f6-4b47-de0b-5cbad7d21ad7"
      },
      "source": [
        "cd deep-learning-from-scratch/ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_ti37fxXkbI",
        "outputId": "89dfd4b4-65ce-4f41-f491-6f1b538531bc"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mch01\u001b[0m/  \u001b[01;34mch03\u001b[0m/  \u001b[01;34mch05\u001b[0m/  \u001b[01;34mch07\u001b[0m/  \u001b[01;34mcommon\u001b[0m/   \u001b[01;32mLICENSE.md\u001b[0m*\n",
            "\u001b[01;34mch02\u001b[0m/  \u001b[01;34mch04\u001b[0m/  \u001b[01;34mch06\u001b[0m/  \u001b[01;34mch08\u001b[0m/  \u001b[01;34mdataset\u001b[0m/  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PwrKs6hXnjV",
        "outputId": "5673e8be-48eb-417d-94ef-e16183660cd9"
      },
      "source": [
        "cd ch06/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch/ch06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj3RBwX4Xr-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fa177d-ec00-4550-cbcb-b3b1aa0130a3"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_norm_gradient_check.py    overfit_dropout.py\n",
            "batch_norm_test.py              overfit_weight_decay.py\n",
            "hyperparameter_optimization.py  weight_init_activation_histogram.py\n",
            "optimizer_compare_mnist.py      weight_init_compare.py\n",
            "optimizer_compare_naive.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6gQ8OIHYydj",
        "outputId": "930273eb-ee6d-4d1c-af74-b0b8ee659b27"
      },
      "source": [
        "cat batch_norm_gradient_check.py "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import sys, os\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "from dataset.mnist import load_mnist\n",
            "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
            "\n",
            "# データの読み込み\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
            "\n",
            "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100], output_size=10,\n",
            "                              use_batchnorm=True)\n",
            "\n",
            "x_batch = x_train[:1]\n",
            "t_batch = t_train[:1]\n",
            "\n",
            "grad_backprop = network.gradient(x_batch, t_batch)\n",
            "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
            "\n",
            "\n",
            "for key in grad_numerical.keys():\n",
            "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
            "    print(key + \":\" + str(diff))"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R-WYUH2Y5l6",
        "outputId": "ba76c815-05a3-4d53-9623-c983a6a912c7"
      },
      "source": [
        "! python batch_norm_gradient_check.py "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading train-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n",
            "Traceback (most recent call last):\n",
            "  File \"batch_norm_gradient_check.py\", line 18, in <module>\n",
            "    grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
            "  File \"../common/multi_layer_net_extend.py\", line 131, in numerical_gradient\n",
            "    grads['W' + str(idx)] = numerical_gradient(loss_W, self.params['W' + str(idx)])\n",
            "  File \"../common/gradient.py\", line 43, in numerical_gradient\n",
            "    fxh1 = f(x) # f(x+h)\n",
            "  File \"../common/multi_layer_net_extend.py\", line 127, in <lambda>\n",
            "    loss_W = lambda W: self.loss(x, t, train_flg=True)\n",
            "  File \"../common/multi_layer_net_extend.py\", line 96, in loss\n",
            "    y = self.predict(x, train_flg)\n",
            "  File \"../common/multi_layer_net_extend.py\", line 88, in predict\n",
            "    x = layer.forward(x)\n",
            "  File \"../common/layers.py\", line 57, in forward\n",
            "    out = np.dot(self.x, self.W) + self.b\n",
            "  File \"<__array_function__ internals>\", line 6, in dot\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3fiW06dYz6W",
        "outputId": "9c2b2918-4240-4c9c-a37a-5d5817432563"
      },
      "source": [
        "cat batch_norm_test.py                   "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import sys, os\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from dataset.mnist import load_mnist\n",
            "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
            "from common.optimizer import SGD, Adam\n",
            "\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
            "\n",
            "# 学習データを削減\n",
            "x_train = x_train[:1000]\n",
            "t_train = t_train[:1000]\n",
            "\n",
            "max_epochs = 20\n",
            "train_size = x_train.shape[0]\n",
            "batch_size = 100\n",
            "learning_rate = 0.01\n",
            "\n",
            "\n",
            "def __train(weight_init_std):\n",
            "    bn_network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10, \n",
            "                                    weight_init_std=weight_init_std, use_batchnorm=True)\n",
            "    network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10,\n",
            "                                weight_init_std=weight_init_std)\n",
            "    optimizer = SGD(lr=learning_rate)\n",
            "    \n",
            "    train_acc_list = []\n",
            "    bn_train_acc_list = []\n",
            "    \n",
            "    iter_per_epoch = max(train_size / batch_size, 1)\n",
            "    epoch_cnt = 0\n",
            "    \n",
            "    for i in range(1000000000):\n",
            "        batch_mask = np.random.choice(train_size, batch_size)\n",
            "        x_batch = x_train[batch_mask]\n",
            "        t_batch = t_train[batch_mask]\n",
            "    \n",
            "        for _network in (bn_network, network):\n",
            "            grads = _network.gradient(x_batch, t_batch)\n",
            "            optimizer.update(_network.params, grads)\n",
            "    \n",
            "        if i % iter_per_epoch == 0:\n",
            "            train_acc = network.accuracy(x_train, t_train)\n",
            "            bn_train_acc = bn_network.accuracy(x_train, t_train)\n",
            "            train_acc_list.append(train_acc)\n",
            "            bn_train_acc_list.append(bn_train_acc)\n",
            "    \n",
            "            print(\"epoch:\" + str(epoch_cnt) + \" | \" + str(train_acc) + \" - \" + str(bn_train_acc))\n",
            "    \n",
            "            epoch_cnt += 1\n",
            "            if epoch_cnt >= max_epochs:\n",
            "                break\n",
            "                \n",
            "    return train_acc_list, bn_train_acc_list\n",
            "\n",
            "\n",
            "# 3.グラフの描画==========\n",
            "weight_scale_list = np.logspace(0, -4, num=16)\n",
            "x = np.arange(max_epochs)\n",
            "\n",
            "for i, w in enumerate(weight_scale_list):\n",
            "    print( \"============== \" + str(i+1) + \"/16\" + \" ==============\")\n",
            "    train_acc_list, bn_train_acc_list = __train(w)\n",
            "    \n",
            "    plt.subplot(4,4,i+1)\n",
            "    plt.title(\"W:\" + str(w))\n",
            "    if i == 15:\n",
            "        plt.plot(x, bn_train_acc_list, label='Batch Normalization', markevery=2)\n",
            "        plt.plot(x, train_acc_list, linestyle = \"--\", label='Normal(without BatchNorm)', markevery=2)\n",
            "    else:\n",
            "        plt.plot(x, bn_train_acc_list, markevery=2)\n",
            "        plt.plot(x, train_acc_list, linestyle=\"--\", markevery=2)\n",
            "\n",
            "    plt.ylim(0, 1.0)\n",
            "    if i % 4:\n",
            "        plt.yticks([])\n",
            "    else:\n",
            "        plt.ylabel(\"accuracy\")\n",
            "    if i < 12:\n",
            "        plt.xticks([])\n",
            "    else:\n",
            "        plt.xlabel(\"epochs\")\n",
            "    plt.legend(loc='lower right')\n",
            "    \n",
            "plt.show()"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mfdtn3AoZqJr",
        "outputId": "0ea0f864-cb02-4b6c-ec4a-d6feefea59f5"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
        "from common.optimizer import SGD, Adam\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 学習データを削減\n",
        "x_train = x_train[:1000]\n",
        "t_train = t_train[:1000]\n",
        "\n",
        "max_epochs = 20\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "def __train(weight_init_std):\n",
        "    bn_network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10, \n",
        "                                    weight_init_std=weight_init_std, use_batchnorm=True)\n",
        "    network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10,\n",
        "                                weight_init_std=weight_init_std)\n",
        "    optimizer = SGD(lr=learning_rate)\n",
        "    \n",
        "    train_acc_list = []\n",
        "    bn_train_acc_list = []\n",
        "    \n",
        "    iter_per_epoch = max(train_size / batch_size, 1)\n",
        "    epoch_cnt = 0\n",
        "    \n",
        "    for i in range(1000000000):\n",
        "        batch_mask = np.random.choice(train_size, batch_size)\n",
        "        x_batch = x_train[batch_mask]\n",
        "        t_batch = t_train[batch_mask]\n",
        "    \n",
        "        for _network in (bn_network, network):\n",
        "            grads = _network.gradient(x_batch, t_batch)\n",
        "            optimizer.update(_network.params, grads)\n",
        "    \n",
        "        if i % iter_per_epoch == 0:\n",
        "            train_acc = network.accuracy(x_train, t_train)\n",
        "            bn_train_acc = bn_network.accuracy(x_train, t_train)\n",
        "            train_acc_list.append(train_acc)\n",
        "            bn_train_acc_list.append(bn_train_acc)\n",
        "    \n",
        "            print(\"epoch:\" + str(epoch_cnt) + \" | \" + str(train_acc) + \" - \" + str(bn_train_acc))\n",
        "    \n",
        "            epoch_cnt += 1\n",
        "            if epoch_cnt >= max_epochs:\n",
        "                break\n",
        "                \n",
        "    return train_acc_list, bn_train_acc_list\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "weight_scale_list = np.logspace(0, -4, num=16)\n",
        "x = np.arange(max_epochs)\n",
        "\n",
        "for i, w in enumerate(weight_scale_list):\n",
        "    print( \"============== \" + str(i+1) + \"/16\" + \" ==============\")\n",
        "    train_acc_list, bn_train_acc_list = __train(w)\n",
        "    \n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.title(\"W:\" + str(w))\n",
        "    if i == 15:\n",
        "        plt.plot(x, bn_train_acc_list, label='Batch Normalization', markevery=2)\n",
        "        plt.plot(x, train_acc_list, linestyle = \"--\", label='Normal(without BatchNorm)', markevery=2)\n",
        "    else:\n",
        "        plt.plot(x, bn_train_acc_list, markevery=2)\n",
        "        plt.plot(x, train_acc_list, linestyle=\"--\", markevery=2)\n",
        "\n",
        "    plt.ylim(0, 1.0)\n",
        "    if i % 4:\n",
        "        plt.yticks([])\n",
        "    else:\n",
        "        plt.ylabel(\"accuracy\")\n",
        "    if i < 12:\n",
        "        plt.xticks([])\n",
        "    else:\n",
        "        plt.xlabel(\"epochs\")\n",
        "    plt.legend(loc='lower right')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============== 1/16 ==============\n",
            "epoch:0 | 0.093 - 0.109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "../common/multi_layer_net_extend.py:101: RuntimeWarning: overflow encountered in square\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
            "../common/multi_layer_net_extend.py:101: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
            "../common/functions.py:32: RuntimeWarning: invalid value encountered in subtract\n",
            "  x = x - np.max(x, axis=-1, keepdims=True)   # オーバーフロー対策\n",
            "../common/layers.py:12: RuntimeWarning: invalid value encountered in less_equal\n",
            "  self.mask = (x <= 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1 | 0.097 - 0.115\n",
            "epoch:2 | 0.097 - 0.115\n",
            "epoch:3 | 0.097 - 0.122\n",
            "epoch:4 | 0.097 - 0.137\n",
            "epoch:5 | 0.097 - 0.144\n",
            "epoch:6 | 0.097 - 0.161\n",
            "epoch:7 | 0.097 - 0.178\n",
            "epoch:8 | 0.097 - 0.197\n",
            "epoch:9 | 0.097 - 0.22\n",
            "epoch:10 | 0.097 - 0.225\n",
            "epoch:11 | 0.097 - 0.248\n",
            "epoch:12 | 0.097 - 0.272\n",
            "epoch:13 | 0.097 - 0.284\n",
            "epoch:14 | 0.097 - 0.294\n",
            "epoch:15 | 0.097 - 0.298\n",
            "epoch:16 | 0.097 - 0.326\n",
            "epoch:17 | 0.097 - 0.336\n",
            "epoch:18 | 0.097 - 0.357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:19 | 0.097 - 0.364\n",
            "============== 2/16 ==============\n",
            "epoch:0 | 0.094 - 0.168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "../common/layers.py:12: RuntimeWarning: invalid value encountered in less_equal\n",
            "  self.mask = (x <= 0)\n",
            "../common/multi_layer_net_extend.py:101: RuntimeWarning: overflow encountered in square\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "../common/multi_layer_net_extend.py:101: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1 | 0.097 - 0.173\n",
            "epoch:2 | 0.097 - 0.206\n",
            "epoch:3 | 0.097 - 0.224\n",
            "epoch:4 | 0.097 - 0.235\n",
            "epoch:5 | 0.097 - 0.258\n",
            "epoch:6 | 0.097 - 0.276\n",
            "epoch:7 | 0.097 - 0.311\n",
            "epoch:8 | 0.097 - 0.334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-669907a8feef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_scale_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"============== \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/16\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" ==============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_train_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-669907a8feef>\u001b[0m in \u001b[0;36m__train\u001b[0;34m(weight_init_std)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miter_per_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mbn_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mbn_train_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn_train_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net_extend.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net_extend.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, train_flg)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Dropout\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"BatchNorm\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, train_flg)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36m__forward\u001b[0;34m(self, x, train_flg)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poufnt4hY1p4",
        "outputId": "ff712c67-f672-40b7-f27d-97a04abf1538"
      },
      "source": [
        "cat hyperparameter_optimization.py"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import sys, os\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from dataset.mnist import load_mnist\n",
            "from common.multi_layer_net import MultiLayerNet\n",
            "from common.util import shuffle_dataset\n",
            "from common.trainer import Trainer\n",
            "\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
            "\n",
            "# 高速化のため訓練データの削減\n",
            "x_train = x_train[:500]\n",
            "t_train = t_train[:500]\n",
            "\n",
            "# 検証データの分離\n",
            "validation_rate = 0.20\n",
            "validation_num = int(x_train.shape[0] * validation_rate)\n",
            "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
            "x_val = x_train[:validation_num]\n",
            "t_val = t_train[:validation_num]\n",
            "x_train = x_train[validation_num:]\n",
            "t_train = t_train[validation_num:]\n",
            "\n",
            "\n",
            "def __train(lr, weight_decay, epocs=50):\n",
            "    network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
            "                            output_size=10, weight_decay_lambda=weight_decay)\n",
            "    trainer = Trainer(network, x_train, t_train, x_val, t_val,\n",
            "                      epochs=epocs, mini_batch_size=100,\n",
            "                      optimizer='sgd', optimizer_param={'lr': lr}, verbose=False)\n",
            "    trainer.train()\n",
            "\n",
            "    return trainer.test_acc_list, trainer.train_acc_list\n",
            "\n",
            "\n",
            "# ハイパーパラメータのランダム探索======================================\n",
            "optimization_trial = 100\n",
            "results_val = {}\n",
            "results_train = {}\n",
            "for _ in range(optimization_trial):\n",
            "    # 探索したハイパーパラメータの範囲を指定===============\n",
            "    weight_decay = 10 ** np.random.uniform(-8, -4)\n",
            "    lr = 10 ** np.random.uniform(-6, -2)\n",
            "    # ================================================\n",
            "\n",
            "    val_acc_list, train_acc_list = __train(lr, weight_decay)\n",
            "    print(\"val acc:\" + str(val_acc_list[-1]) + \" | lr:\" + str(lr) + \", weight decay:\" + str(weight_decay))\n",
            "    key = \"lr:\" + str(lr) + \", weight decay:\" + str(weight_decay)\n",
            "    results_val[key] = val_acc_list\n",
            "    results_train[key] = train_acc_list\n",
            "\n",
            "# グラフの描画========================================================\n",
            "print(\"=========== Hyper-Parameter Optimization Result ===========\")\n",
            "graph_draw_num = 20\n",
            "col_num = 5\n",
            "row_num = int(np.ceil(graph_draw_num / col_num))\n",
            "i = 0\n",
            "\n",
            "for key, val_acc_list in sorted(results_val.items(), key=lambda x:x[1][-1], reverse=True):\n",
            "    print(\"Best-\" + str(i+1) + \"(val acc:\" + str(val_acc_list[-1]) + \") | \" + key)\n",
            "\n",
            "    plt.subplot(row_num, col_num, i+1)\n",
            "    plt.title(\"Best-\" + str(i+1))\n",
            "    plt.ylim(0.0, 1.0)\n",
            "    if i % 5: plt.yticks([])\n",
            "    plt.xticks([])\n",
            "    x = np.arange(len(val_acc_list))\n",
            "    plt.plot(x, val_acc_list)\n",
            "    plt.plot(x, results_train[key], \"--\")\n",
            "    i += 1\n",
            "\n",
            "    if i >= graph_draw_num:\n",
            "        break\n",
            "\n",
            "plt.show()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "A11Q8dfzaE5W",
        "outputId": "c7889ab8-2f4c-479c-df86-81d44868bfe6"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net import MultiLayerNet\n",
        "from common.util import shuffle_dataset\n",
        "from common.trainer import Trainer\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 高速化のため訓練データの削減\n",
        "x_train = x_train[:500]\n",
        "t_train = t_train[:500]\n",
        "\n",
        "# 検証データの分離\n",
        "validation_rate = 0.20\n",
        "validation_num = int(x_train.shape[0] * validation_rate)\n",
        "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
        "x_val = x_train[:validation_num]\n",
        "t_val = t_train[:validation_num]\n",
        "x_train = x_train[validation_num:]\n",
        "t_train = t_train[validation_num:]\n",
        "\n",
        "\n",
        "def __train(lr, weight_decay, epocs=50):\n",
        "    network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
        "                            output_size=10, weight_decay_lambda=weight_decay)\n",
        "    trainer = Trainer(network, x_train, t_train, x_val, t_val,\n",
        "                      epochs=epocs, mini_batch_size=100,\n",
        "                      optimizer='sgd', optimizer_param={'lr': lr}, verbose=False)\n",
        "    trainer.train()\n",
        "\n",
        "    return trainer.test_acc_list, trainer.train_acc_list\n",
        "\n",
        "\n",
        "# ハイパーパラメータのランダム探索======================================\n",
        "optimization_trial = 100\n",
        "results_val = {}\n",
        "results_train = {}\n",
        "for _ in range(optimization_trial):\n",
        "    # 探索したハイパーパラメータの範囲を指定===============\n",
        "    weight_decay = 10 ** np.random.uniform(-8, -4)\n",
        "    lr = 10 ** np.random.uniform(-6, -2)\n",
        "    # ================================================\n",
        "\n",
        "    val_acc_list, train_acc_list = __train(lr, weight_decay)\n",
        "    print(\"val acc:\" + str(val_acc_list[-1]) + \" | lr:\" + str(lr) + \", weight decay:\" + str(weight_decay))\n",
        "    key = \"lr:\" + str(lr) + \", weight decay:\" + str(weight_decay)\n",
        "    results_val[key] = val_acc_list\n",
        "    results_train[key] = train_acc_list\n",
        "\n",
        "# グラフの描画========================================================\n",
        "print(\"=========== Hyper-Parameter Optimization Result ===========\")\n",
        "graph_draw_num = 20\n",
        "col_num = 5\n",
        "row_num = int(np.ceil(graph_draw_num / col_num))\n",
        "i = 0\n",
        "\n",
        "for key, val_acc_list in sorted(results_val.items(), key=lambda x:x[1][-1], reverse=True):\n",
        "    print(\"Best-\" + str(i+1) + \"(val acc:\" + str(val_acc_list[-1]) + \") | \" + key)\n",
        "\n",
        "    plt.subplot(row_num, col_num, i+1)\n",
        "    plt.title(\"Best-\" + str(i+1))\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    if i % 5: plt.yticks([])\n",
        "    plt.xticks([])\n",
        "    x = np.arange(len(val_acc_list))\n",
        "    plt.plot(x, val_acc_list)\n",
        "    plt.plot(x, results_train[key], \"--\")\n",
        "    i += 1\n",
        "\n",
        "    if i >= graph_draw_num:\n",
        "        break\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val acc:0.11 | lr:2.03989013381823e-05, weight decay:3.536978035073959e-07\n",
            "val acc:0.05 | lr:6.940298716552199e-05, weight decay:2.406704819903105e-08\n",
            "val acc:0.13 | lr:1.80654767494667e-06, weight decay:2.1714960161526056e-08\n",
            "val acc:0.2 | lr:0.0006196723350043387, weight decay:9.649678950643666e-06\n",
            "val acc:0.16 | lr:8.263034098268072e-05, weight decay:3.550423768263382e-07\n",
            "val acc:0.06 | lr:0.0003266614444757589, weight decay:1.6685382653916082e-08\n",
            "val acc:0.11 | lr:0.000540736789032497, weight decay:2.9009873559081692e-05\n",
            "val acc:0.14 | lr:2.6986575049184545e-05, weight decay:3.189629950622096e-07\n",
            "val acc:0.8 | lr:0.006182563264407069, weight decay:1.4393804806805768e-06\n",
            "val acc:0.12 | lr:0.0003302485935534036, weight decay:4.651374684073988e-05\n",
            "val acc:0.2 | lr:0.0010574076272073325, weight decay:6.245688000877473e-06\n",
            "val acc:0.03 | lr:4.305490105019575e-05, weight decay:7.252907419326312e-08\n",
            "val acc:0.14 | lr:0.000490774067085083, weight decay:5.03264414261917e-05\n",
            "val acc:0.21 | lr:0.0007227569220770877, weight decay:3.1013200625212335e-05\n",
            "val acc:0.89 | lr:0.009211101854089583, weight decay:8.20261281865502e-08\n",
            "val acc:0.07 | lr:5.754562967391471e-06, weight decay:2.4903906055333363e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a0beec8dc8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# ================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val acc:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" | lr:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", weight decay:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lr:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", weight decay:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-a0beec8dc8a0>\u001b[0m in \u001b[0;36m__train\u001b[0;34m(lr, weight_decay, epocs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                       optimizer='sgd', optimizer_param={'lr': lr}, verbose=False)\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# 設定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSywikmTY17H",
        "outputId": "74243e3f-7242-47c8-b45d-253097165102"
      },
      "source": [
        "cat optimizer_compare_mnist.py"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import os\n",
            "import sys\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import matplotlib.pyplot as plt\n",
            "from dataset.mnist import load_mnist\n",
            "from common.util import smooth_curve\n",
            "from common.multi_layer_net import MultiLayerNet\n",
            "from common.optimizer import *\n",
            "\n",
            "\n",
            "# 0:MNISTデータの読み込み==========\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
            "\n",
            "train_size = x_train.shape[0]\n",
            "batch_size = 128\n",
            "max_iterations = 2000\n",
            "\n",
            "\n",
            "# 1:実験の設定==========\n",
            "optimizers = {}\n",
            "optimizers['SGD'] = SGD()\n",
            "optimizers['Momentum'] = Momentum()\n",
            "optimizers['AdaGrad'] = AdaGrad()\n",
            "optimizers['Adam'] = Adam()\n",
            "#optimizers['RMSprop'] = RMSprop()\n",
            "\n",
            "networks = {}\n",
            "train_loss = {}\n",
            "for key in optimizers.keys():\n",
            "    networks[key] = MultiLayerNet(\n",
            "        input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
            "        output_size=10)\n",
            "    train_loss[key] = []    \n",
            "\n",
            "\n",
            "# 2:訓練の開始==========\n",
            "for i in range(max_iterations):\n",
            "    batch_mask = np.random.choice(train_size, batch_size)\n",
            "    x_batch = x_train[batch_mask]\n",
            "    t_batch = t_train[batch_mask]\n",
            "    \n",
            "    for key in optimizers.keys():\n",
            "        grads = networks[key].gradient(x_batch, t_batch)\n",
            "        optimizers[key].update(networks[key].params, grads)\n",
            "    \n",
            "        loss = networks[key].loss(x_batch, t_batch)\n",
            "        train_loss[key].append(loss)\n",
            "    \n",
            "    if i % 100 == 0:\n",
            "        print( \"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
            "        for key in optimizers.keys():\n",
            "            loss = networks[key].loss(x_batch, t_batch)\n",
            "            print(key + \":\" + str(loss))\n",
            "\n",
            "\n",
            "# 3.グラフの描画==========\n",
            "markers = {\"SGD\": \"o\", \"Momentum\": \"x\", \"AdaGrad\": \"s\", \"Adam\": \"D\"}\n",
            "x = np.arange(max_iterations)\n",
            "for key in optimizers.keys():\n",
            "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
            "plt.xlabel(\"iterations\")\n",
            "plt.ylabel(\"loss\")\n",
            "plt.ylim(0, 1)\n",
            "plt.legend()\n",
            "plt.show()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "SsxH6T2_adTn",
        "outputId": "11041276-7cd0-40a2-d522-7e4e5b976f34"
      },
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.util import smooth_curve\n",
        "from common.multi_layer_net import MultiLayerNet\n",
        "from common.optimizer import *\n",
        "\n",
        "\n",
        "# 0:MNISTデータの読み込み==========\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 128\n",
        "max_iterations = 2000\n",
        "\n",
        "\n",
        "# 1:実験の設定==========\n",
        "optimizers = {}\n",
        "optimizers['SGD'] = SGD()\n",
        "optimizers['Momentum'] = Momentum()\n",
        "optimizers['AdaGrad'] = AdaGrad()\n",
        "optimizers['Adam'] = Adam()\n",
        "#optimizers['RMSprop'] = RMSprop()\n",
        "\n",
        "networks = {}\n",
        "train_loss = {}\n",
        "for key in optimizers.keys():\n",
        "    networks[key] = MultiLayerNet(\n",
        "        input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
        "        output_size=10)\n",
        "    train_loss[key] = []    \n",
        "\n",
        "\n",
        "# 2:訓練の開始==========\n",
        "for i in range(max_iterations):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    for key in optimizers.keys():\n",
        "        grads = networks[key].gradient(x_batch, t_batch)\n",
        "        optimizers[key].update(networks[key].params, grads)\n",
        "    \n",
        "        loss = networks[key].loss(x_batch, t_batch)\n",
        "        train_loss[key].append(loss)\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print( \"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
        "        for key in optimizers.keys():\n",
        "            loss = networks[key].loss(x_batch, t_batch)\n",
        "            print(key + \":\" + str(loss))\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "markers = {\"SGD\": \"o\", \"Momentum\": \"x\", \"AdaGrad\": \"s\", \"Adam\": \"D\"}\n",
        "x = np.arange(max_iterations)\n",
        "for key in optimizers.keys():\n",
        "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========iteration:0===========\n",
            "SGD:2.4806445148326595\n",
            "Momentum:2.3608465240599465\n",
            "AdaGrad:2.629664261287231\n",
            "Adam:2.2435617243199784\n",
            "===========iteration:100===========\n",
            "SGD:1.6614126495753103\n",
            "Momentum:0.5273129046097823\n",
            "AdaGrad:0.19542624711655388\n",
            "Adam:0.39653586089956194\n",
            "===========iteration:200===========\n",
            "SGD:0.8507796329342849\n",
            "Momentum:0.2321530597679202\n",
            "AdaGrad:0.09744304703522598\n",
            "Adam:0.2054122452170049\n",
            "===========iteration:300===========\n",
            "SGD:0.5900524893293719\n",
            "Momentum:0.24267327555724802\n",
            "AdaGrad:0.10366266738618064\n",
            "Adam:0.17460189495934963\n",
            "===========iteration:400===========\n",
            "SGD:0.43970834397286634\n",
            "Momentum:0.1914740460404803\n",
            "AdaGrad:0.051681588882469515\n",
            "Adam:0.1887245641486986\n",
            "===========iteration:500===========\n",
            "SGD:0.46508152541520037\n",
            "Momentum:0.247404983540564\n",
            "AdaGrad:0.06990730887841828\n",
            "Adam:0.17162499400210457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-77d2c7434209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# 設定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqDKok1RY2I-",
        "outputId": "806c45eb-269a-4412-943b-77ed8f26bb62"
      },
      "source": [
        "cat optimizer_compare_naive.py"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import sys, os\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from collections import OrderedDict\n",
            "from common.optimizer import *\n",
            "\n",
            "\n",
            "def f(x, y):\n",
            "    return x**2 / 20.0 + y**2\n",
            "\n",
            "\n",
            "def df(x, y):\n",
            "    return x / 10.0, 2.0*y\n",
            "\n",
            "init_pos = (-7.0, 2.0)\n",
            "params = {}\n",
            "params['x'], params['y'] = init_pos[0], init_pos[1]\n",
            "grads = {}\n",
            "grads['x'], grads['y'] = 0, 0\n",
            "\n",
            "\n",
            "optimizers = OrderedDict()\n",
            "optimizers[\"SGD\"] = SGD(lr=0.95)\n",
            "optimizers[\"Momentum\"] = Momentum(lr=0.1)\n",
            "optimizers[\"AdaGrad\"] = AdaGrad(lr=1.5)\n",
            "optimizers[\"Adam\"] = Adam(lr=0.3)\n",
            "\n",
            "idx = 1\n",
            "\n",
            "for key in optimizers:\n",
            "    optimizer = optimizers[key]\n",
            "    x_history = []\n",
            "    y_history = []\n",
            "    params['x'], params['y'] = init_pos[0], init_pos[1]\n",
            "    \n",
            "    for i in range(30):\n",
            "        x_history.append(params['x'])\n",
            "        y_history.append(params['y'])\n",
            "        \n",
            "        grads['x'], grads['y'] = df(params['x'], params['y'])\n",
            "        optimizer.update(params, grads)\n",
            "    \n",
            "\n",
            "    x = np.arange(-10, 10, 0.01)\n",
            "    y = np.arange(-5, 5, 0.01)\n",
            "    \n",
            "    X, Y = np.meshgrid(x, y) \n",
            "    Z = f(X, Y)\n",
            "    \n",
            "    # for simple contour line  \n",
            "    mask = Z > 7\n",
            "    Z[mask] = 0\n",
            "    \n",
            "    # plot \n",
            "    plt.subplot(2, 2, idx)\n",
            "    idx += 1\n",
            "    plt.plot(x_history, y_history, 'o-', color=\"red\")\n",
            "    plt.contour(X, Y, Z)\n",
            "    plt.ylim(-10, 10)\n",
            "    plt.xlim(-10, 10)\n",
            "    plt.plot(0, 0, '+')\n",
            "    #colorbar()\n",
            "    #spring()\n",
            "    plt.title(key)\n",
            "    plt.xlabel(\"x\")\n",
            "    plt.ylabel(\"y\")\n",
            "    \n",
            "plt.show()"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Gth61R5eaqJU",
        "outputId": "08812129-4982-4158-e166-3fa31b9547fb"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from common.optimizer import *\n",
        "\n",
        "\n",
        "def f(x, y):\n",
        "    return x**2 / 20.0 + y**2\n",
        "\n",
        "\n",
        "def df(x, y):\n",
        "    return x / 10.0, 2.0*y\n",
        "\n",
        "init_pos = (-7.0, 2.0)\n",
        "params = {}\n",
        "params['x'], params['y'] = init_pos[0], init_pos[1]\n",
        "grads = {}\n",
        "grads['x'], grads['y'] = 0, 0\n",
        "\n",
        "\n",
        "optimizers = OrderedDict()\n",
        "optimizers[\"SGD\"] = SGD(lr=0.95)\n",
        "optimizers[\"Momentum\"] = Momentum(lr=0.1)\n",
        "optimizers[\"AdaGrad\"] = AdaGrad(lr=1.5)\n",
        "optimizers[\"Adam\"] = Adam(lr=0.3)\n",
        "\n",
        "idx = 1\n",
        "\n",
        "for key in optimizers:\n",
        "    optimizer = optimizers[key]\n",
        "    x_history = []\n",
        "    y_history = []\n",
        "    params['x'], params['y'] = init_pos[0], init_pos[1]\n",
        "    \n",
        "    for i in range(30):\n",
        "        x_history.append(params['x'])\n",
        "        y_history.append(params['y'])\n",
        "        \n",
        "        grads['x'], grads['y'] = df(params['x'], params['y'])\n",
        "        optimizer.update(params, grads)\n",
        "    \n",
        "\n",
        "    x = np.arange(-10, 10, 0.01)\n",
        "    y = np.arange(-5, 5, 0.01)\n",
        "    \n",
        "    X, Y = np.meshgrid(x, y) \n",
        "    Z = f(X, Y)\n",
        "    \n",
        "    # for simple contour line  \n",
        "    mask = Z > 7\n",
        "    Z[mask] = 0\n",
        "    \n",
        "    # plot \n",
        "    plt.subplot(2, 2, idx)\n",
        "    idx += 1\n",
        "    plt.plot(x_history, y_history, 'o-', color=\"red\")\n",
        "    plt.contour(X, Y, Z)\n",
        "    plt.ylim(-10, 10)\n",
        "    plt.xlim(-10, 10)\n",
        "    plt.plot(0, 0, '+')\n",
        "    #colorbar()\n",
        "    #spring()\n",
        "    plt.title(key)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCh-RkWTY2VS",
        "outputId": "e79f1a09-e759-4fc3-ff94-59fb648e8304"
      },
      "source": [
        "cat overfit_dropout.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import os\n",
            "import sys\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from dataset.mnist import load_mnist\n",
            "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
            "from common.trainer import Trainer\n",
            "\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
            "\n",
            "# 過学習を再現するために、学習データを削減\n",
            "x_train = x_train[:300]\n",
            "t_train = t_train[:300]\n",
            "\n",
            "# Dropuoutの有無、割り合いの設定 ========================\n",
            "use_dropout = True  # Dropoutなしのときの場合はFalseに\n",
            "dropout_ratio = 0.2\n",
            "# ====================================================\n",
            "\n",
            "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
            "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
            "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
            "                  epochs=301, mini_batch_size=100,\n",
            "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
            "trainer.train()\n",
            "\n",
            "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
            "\n",
            "# グラフの描画==========\n",
            "markers = {'train': 'o', 'test': 's'}\n",
            "x = np.arange(len(train_acc_list))\n",
            "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
            "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
            "plt.xlabel(\"epochs\")\n",
            "plt.ylabel(\"accuracy\")\n",
            "plt.ylim(0, 1.0)\n",
            "plt.legend(loc='lower right')\n",
            "plt.show()"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yw7emYa9aub_",
        "outputId": "bad06d39-6275-4350-e167-cc4ffb8f8bc5"
      },
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
        "from common.trainer import Trainer\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 過学習を再現するために、学習データを削減\n",
        "x_train = x_train[:300]\n",
        "t_train = t_train[:300]\n",
        "\n",
        "# Dropuoutの有無、割り合いの設定 ========================\n",
        "use_dropout = True  # Dropoutなしのときの場合はFalseに\n",
        "dropout_ratio = 0.2\n",
        "# ====================================================\n",
        "\n",
        "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
        "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=301, mini_batch_size=100,\n",
        "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
        "trainer.train()\n",
        "\n",
        "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
        "\n",
        "# グラフの描画==========\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss:2.316339956931076\n",
            "=== epoch:1, train acc:0.10666666666666667, test acc:0.0991 ===\n",
            "train loss:2.3052030414569074\n",
            "train loss:2.31677335021865\n",
            "train loss:2.3003894137044902\n",
            "=== epoch:2, train acc:0.10666666666666667, test acc:0.0988 ===\n",
            "train loss:2.3087303544336186\n",
            "train loss:2.30191785164283\n",
            "train loss:2.3009418723940467\n",
            "=== epoch:3, train acc:0.10666666666666667, test acc:0.0993 ===\n",
            "train loss:2.2977622822673682\n",
            "train loss:2.3067417179853598\n",
            "train loss:2.307407168608408\n",
            "=== epoch:4, train acc:0.10666666666666667, test acc:0.0994 ===\n",
            "train loss:2.3156900586857185\n",
            "train loss:2.3043863882350517\n",
            "train loss:2.3100071318695807\n",
            "=== epoch:5, train acc:0.11, test acc:0.1001 ===\n",
            "train loss:2.319287640570463\n",
            "train loss:2.285280682577487\n",
            "train loss:2.286772346488855\n",
            "=== epoch:6, train acc:0.11, test acc:0.1001 ===\n",
            "train loss:2.3028315045144283\n",
            "train loss:2.2915949847336567\n",
            "train loss:2.292870798023326\n",
            "=== epoch:7, train acc:0.11, test acc:0.1006 ===\n",
            "train loss:2.2958566687050093\n",
            "train loss:2.310072595349193\n",
            "train loss:2.3041618683571614\n",
            "=== epoch:8, train acc:0.11333333333333333, test acc:0.1014 ===\n",
            "train loss:2.2925143368245595\n",
            "train loss:2.2962767450139476\n",
            "train loss:2.28996035526671\n",
            "=== epoch:9, train acc:0.12, test acc:0.1015 ===\n",
            "train loss:2.300507938998197\n",
            "train loss:2.288363042433221\n",
            "train loss:2.301726802169853\n",
            "=== epoch:10, train acc:0.12, test acc:0.1015 ===\n",
            "train loss:2.3049598702426324\n",
            "train loss:2.289834039316695\n",
            "train loss:2.3002370303339963\n",
            "=== epoch:11, train acc:0.12333333333333334, test acc:0.1023 ===\n",
            "train loss:2.3044781868330695\n",
            "train loss:2.2942910576289\n",
            "train loss:2.3003326748509956\n",
            "=== epoch:12, train acc:0.13, test acc:0.1033 ===\n",
            "train loss:2.298160378378688\n",
            "train loss:2.2899122018783293\n",
            "train loss:2.2982983222406133\n",
            "=== epoch:13, train acc:0.13, test acc:0.1041 ===\n",
            "train loss:2.2882365315988396\n",
            "train loss:2.2957639919005053\n",
            "train loss:2.298985686087093\n",
            "=== epoch:14, train acc:0.13333333333333333, test acc:0.1065 ===\n",
            "train loss:2.2842675857187147\n",
            "train loss:2.2936372209481837\n",
            "train loss:2.297750770810255\n",
            "=== epoch:15, train acc:0.13333333333333333, test acc:0.1085 ===\n",
            "train loss:2.2917256379906443\n",
            "train loss:2.2779450627460465\n",
            "train loss:2.2858676707402443\n",
            "=== epoch:16, train acc:0.13333333333333333, test acc:0.111 ===\n",
            "train loss:2.29023655546013\n",
            "train loss:2.29206094619196\n",
            "train loss:2.2975690989426036\n",
            "=== epoch:17, train acc:0.13666666666666666, test acc:0.1141 ===\n",
            "train loss:2.2925313871498245\n",
            "train loss:2.2897766054436643\n",
            "train loss:2.290698978919191\n",
            "=== epoch:18, train acc:0.14666666666666667, test acc:0.1166 ===\n",
            "train loss:2.281008954198616\n",
            "train loss:2.2817841208807934\n",
            "train loss:2.2820853793649367\n",
            "=== epoch:19, train acc:0.15, test acc:0.1168 ===\n",
            "train loss:2.283790176443897\n",
            "train loss:2.2730738643933064\n",
            "train loss:2.277690776439685\n",
            "=== epoch:20, train acc:0.14666666666666667, test acc:0.1169 ===\n",
            "train loss:2.2864652946723276\n",
            "train loss:2.2800337418155836\n",
            "train loss:2.2799777361252067\n",
            "=== epoch:21, train acc:0.15, test acc:0.1181 ===\n",
            "train loss:2.2878404423503733\n",
            "train loss:2.288462674533835\n",
            "train loss:2.2844018446469114\n",
            "=== epoch:22, train acc:0.16, test acc:0.123 ===\n",
            "train loss:2.284404065419922\n",
            "train loss:2.2820774467377865\n",
            "train loss:2.2859991615642876\n",
            "=== epoch:23, train acc:0.17666666666666667, test acc:0.1228 ===\n",
            "train loss:2.290116766892342\n",
            "train loss:2.2823462752136026\n",
            "train loss:2.274830685031003\n",
            "=== epoch:24, train acc:0.17, test acc:0.1225 ===\n",
            "train loss:2.289643029656428\n",
            "train loss:2.281149356970231\n",
            "train loss:2.28557439014106\n",
            "=== epoch:25, train acc:0.17, test acc:0.1236 ===\n",
            "train loss:2.275566019944875\n",
            "train loss:2.2795953874181993\n",
            "train loss:2.278705445109117\n",
            "=== epoch:26, train acc:0.17333333333333334, test acc:0.1259 ===\n",
            "train loss:2.2795345665733056\n",
            "train loss:2.275898949598355\n",
            "train loss:2.285380830504957\n",
            "=== epoch:27, train acc:0.17333333333333334, test acc:0.129 ===\n",
            "train loss:2.2880145273698873\n",
            "train loss:2.283571282091286\n",
            "train loss:2.2851273561338696\n",
            "=== epoch:28, train acc:0.18666666666666668, test acc:0.1331 ===\n",
            "train loss:2.2808714835148076\n",
            "train loss:2.2725362760654577\n",
            "train loss:2.2759975824090883\n",
            "=== epoch:29, train acc:0.18666666666666668, test acc:0.1348 ===\n",
            "train loss:2.2798800888886444\n",
            "train loss:2.269882004071811\n",
            "train loss:2.2740532728161216\n",
            "=== epoch:30, train acc:0.18333333333333332, test acc:0.133 ===\n",
            "train loss:2.279944030854074\n",
            "train loss:2.273213873974655\n",
            "train loss:2.259723543564566\n",
            "=== epoch:31, train acc:0.18333333333333332, test acc:0.129 ===\n",
            "train loss:2.2806310872603777\n",
            "train loss:2.2751125221845796\n",
            "train loss:2.2843093934135497\n",
            "=== epoch:32, train acc:0.18, test acc:0.1331 ===\n",
            "train loss:2.2791037227487787\n",
            "train loss:2.2563362055443195\n",
            "train loss:2.266660650906676\n",
            "=== epoch:33, train acc:0.18, test acc:0.1363 ===\n",
            "train loss:2.256528583155565\n",
            "train loss:2.275755207230461\n",
            "train loss:2.2754835106651\n",
            "=== epoch:34, train acc:0.18666666666666668, test acc:0.1397 ===\n",
            "train loss:2.271713184019245\n",
            "train loss:2.2837666197243975\n",
            "train loss:2.2676273461386534\n",
            "=== epoch:35, train acc:0.19666666666666666, test acc:0.1421 ===\n",
            "train loss:2.278768809145676\n",
            "train loss:2.2852764335819713\n",
            "train loss:2.2679422702675214\n",
            "=== epoch:36, train acc:0.2, test acc:0.1497 ===\n",
            "train loss:2.273950250717521\n",
            "train loss:2.2707079193887276\n",
            "train loss:2.277031021711574\n",
            "=== epoch:37, train acc:0.21, test acc:0.1531 ===\n",
            "train loss:2.280891223970162\n",
            "train loss:2.2664704920008476\n",
            "train loss:2.277229544853896\n",
            "=== epoch:38, train acc:0.21666666666666667, test acc:0.1628 ===\n",
            "train loss:2.266675338384342\n",
            "train loss:2.2588420216104494\n",
            "train loss:2.2708961266187653\n",
            "=== epoch:39, train acc:0.23, test acc:0.1651 ===\n",
            "train loss:2.2617524918980774\n",
            "train loss:2.269600973594989\n",
            "train loss:2.2701295607276295\n",
            "=== epoch:40, train acc:0.22333333333333333, test acc:0.1669 ===\n",
            "train loss:2.272682275117237\n",
            "train loss:2.2811903007552714\n",
            "train loss:2.2748292602571176\n",
            "=== epoch:41, train acc:0.22333333333333333, test acc:0.174 ===\n",
            "train loss:2.2816861282734378\n",
            "train loss:2.270444915859358\n",
            "train loss:2.271539458116943\n",
            "=== epoch:42, train acc:0.23666666666666666, test acc:0.1831 ===\n",
            "train loss:2.249865024503901\n",
            "train loss:2.2592299134563665\n",
            "train loss:2.2587812953492237\n",
            "=== epoch:43, train acc:0.23333333333333334, test acc:0.1837 ===\n",
            "train loss:2.257497315700796\n",
            "train loss:2.2655068693427522\n",
            "train loss:2.2615796113558893\n",
            "=== epoch:44, train acc:0.23666666666666666, test acc:0.1895 ===\n",
            "train loss:2.263649979923084\n",
            "train loss:2.2641688159293993\n",
            "train loss:2.2590020940986015\n",
            "=== epoch:45, train acc:0.23666666666666666, test acc:0.1953 ===\n",
            "train loss:2.265699403522609\n",
            "train loss:2.2638597162697565\n",
            "train loss:2.250014353885822\n",
            "=== epoch:46, train acc:0.24333333333333335, test acc:0.2012 ===\n",
            "train loss:2.2665631667744837\n",
            "train loss:2.2655346192845705\n",
            "train loss:2.246042661299262\n",
            "=== epoch:47, train acc:0.24333333333333335, test acc:0.2051 ===\n",
            "train loss:2.264188651448578\n",
            "train loss:2.259016017971072\n",
            "train loss:2.258580124372003\n",
            "=== epoch:48, train acc:0.24666666666666667, test acc:0.2068 ===\n",
            "train loss:2.260382288725191\n",
            "train loss:2.2659243814855556\n",
            "train loss:2.2574960145717577\n",
            "=== epoch:49, train acc:0.2633333333333333, test acc:0.2156 ===\n",
            "train loss:2.271708900991132\n",
            "train loss:2.26214517644076\n",
            "train loss:2.2586365203015815\n",
            "=== epoch:50, train acc:0.26, test acc:0.2169 ===\n",
            "train loss:2.251784805109442\n",
            "train loss:2.2589610354200618\n",
            "train loss:2.256080482246732\n",
            "=== epoch:51, train acc:0.27, test acc:0.2225 ===\n",
            "train loss:2.2534539805754146\n",
            "train loss:2.257368157596977\n",
            "train loss:2.259313591515758\n",
            "=== epoch:52, train acc:0.26666666666666666, test acc:0.2233 ===\n",
            "train loss:2.257115144854908\n",
            "train loss:2.263629579667661\n",
            "train loss:2.251153502349765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9c6fd4f10cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m301\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                   optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net_extend.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net_extend.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, train_flg)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYqww5MlY2nr",
        "outputId": "9b77e6d0-0ef6-426a-d05b-20b2de361a03"
      },
      "source": [
        "cat overfit_weight_decay.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import os\n",
            "import sys\n",
            "\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from dataset.mnist import load_mnist\n",
            "from common.multi_layer_net import MultiLayerNet\n",
            "from common.optimizer import SGD\n",
            "\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
            "\n",
            "# 過学習を再現するために、学習データを削減\n",
            "x_train = x_train[:300]\n",
            "t_train = t_train[:300]\n",
            "\n",
            "# weight decay（荷重減衰）の設定 =======================\n",
            "#weight_decay_lambda = 0 # weight decayを使用しない場合\n",
            "weight_decay_lambda = 0.1\n",
            "# ====================================================\n",
            "\n",
            "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
            "                        weight_decay_lambda=weight_decay_lambda)\n",
            "optimizer = SGD(lr=0.01)\n",
            "\n",
            "max_epochs = 201\n",
            "train_size = x_train.shape[0]\n",
            "batch_size = 100\n",
            "\n",
            "train_loss_list = []\n",
            "train_acc_list = []\n",
            "test_acc_list = []\n",
            "\n",
            "iter_per_epoch = max(train_size / batch_size, 1)\n",
            "epoch_cnt = 0\n",
            "\n",
            "for i in range(1000000000):\n",
            "    batch_mask = np.random.choice(train_size, batch_size)\n",
            "    x_batch = x_train[batch_mask]\n",
            "    t_batch = t_train[batch_mask]\n",
            "\n",
            "    grads = network.gradient(x_batch, t_batch)\n",
            "    optimizer.update(network.params, grads)\n",
            "\n",
            "    if i % iter_per_epoch == 0:\n",
            "        train_acc = network.accuracy(x_train, t_train)\n",
            "        test_acc = network.accuracy(x_test, t_test)\n",
            "        train_acc_list.append(train_acc)\n",
            "        test_acc_list.append(test_acc)\n",
            "\n",
            "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
            "\n",
            "        epoch_cnt += 1\n",
            "        if epoch_cnt >= max_epochs:\n",
            "            break\n",
            "\n",
            "\n",
            "# 3.グラフの描画==========\n",
            "markers = {'train': 'o', 'test': 's'}\n",
            "x = np.arange(max_epochs)\n",
            "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
            "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
            "plt.xlabel(\"epochs\")\n",
            "plt.ylabel(\"accuracy\")\n",
            "plt.ylim(0, 1.0)\n",
            "plt.legend(loc='lower right')\n",
            "plt.show()"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "7xT-lZp-a2_Y",
        "outputId": "63439dd6-6ac0-4e80-8f5d-70f897706deb"
      },
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net import MultiLayerNet\n",
        "from common.optimizer import SGD\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 過学習を再現するために、学習データを削減\n",
        "x_train = x_train[:300]\n",
        "t_train = t_train[:300]\n",
        "\n",
        "# weight decay（荷重減衰）の設定 =======================\n",
        "#weight_decay_lambda = 0 # weight decayを使用しない場合\n",
        "weight_decay_lambda = 0.1\n",
        "# ====================================================\n",
        "\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
        "                        weight_decay_lambda=weight_decay_lambda)\n",
        "optimizer = SGD(lr=0.01)\n",
        "\n",
        "max_epochs = 201\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "epoch_cnt = 0\n",
        "\n",
        "for i in range(1000000000):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    grads = network.gradient(x_batch, t_batch)\n",
        "    optimizer.update(network.params, grads)\n",
        "\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
        "\n",
        "        epoch_cnt += 1\n",
        "        if epoch_cnt >= max_epochs:\n",
        "            break\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0, train acc:0.08666666666666667, test acc:0.105\n",
            "epoch:1, train acc:0.10333333333333333, test acc:0.115\n",
            "epoch:2, train acc:0.11, test acc:0.1245\n",
            "epoch:3, train acc:0.13666666666666666, test acc:0.1335\n",
            "epoch:4, train acc:0.19333333333333333, test acc:0.1535\n",
            "epoch:5, train acc:0.23333333333333334, test acc:0.17\n",
            "epoch:6, train acc:0.24, test acc:0.1776\n",
            "epoch:7, train acc:0.23666666666666666, test acc:0.1816\n",
            "epoch:8, train acc:0.29, test acc:0.211\n",
            "epoch:9, train acc:0.33, test acc:0.2279\n",
            "epoch:10, train acc:0.31666666666666665, test acc:0.2414\n",
            "epoch:11, train acc:0.35333333333333333, test acc:0.2542\n",
            "epoch:12, train acc:0.37, test acc:0.261\n",
            "epoch:13, train acc:0.38666666666666666, test acc:0.2839\n",
            "epoch:14, train acc:0.4, test acc:0.2958\n",
            "epoch:15, train acc:0.41, test acc:0.3113\n",
            "epoch:16, train acc:0.41, test acc:0.3103\n",
            "epoch:17, train acc:0.4166666666666667, test acc:0.3337\n",
            "epoch:18, train acc:0.43, test acc:0.338\n",
            "epoch:19, train acc:0.45, test acc:0.3562\n",
            "epoch:20, train acc:0.4666666666666667, test acc:0.3654\n",
            "epoch:21, train acc:0.4766666666666667, test acc:0.3734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0c3711c6f5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miter_per_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVF8aSbgY22Q",
        "outputId": "2a7a1fe0-ee7d-4897-fa7c-ca1369af29cf"
      },
      "source": [
        "cat weight_init_activation_histogram.py"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "\n",
            "def sigmoid(x):\n",
            "    return 1 / (1 + np.exp(-x))\n",
            "\n",
            "\n",
            "def ReLU(x):\n",
            "    return np.maximum(0, x)\n",
            "\n",
            "\n",
            "def tanh(x):\n",
            "    return np.tanh(x)\n",
            "    \n",
            "input_data = np.random.randn(1000, 100)  # 1000個のデータ\n",
            "node_num = 100  # 各隠れ層のノード（ニューロン）の数\n",
            "hidden_layer_size = 5  # 隠れ層が5層\n",
            "activations = {}  # ここにアクティベーションの結果を格納する\n",
            "\n",
            "x = input_data\n",
            "\n",
            "for i in range(hidden_layer_size):\n",
            "    if i != 0:\n",
            "        x = activations[i-1]\n",
            "\n",
            "    # 初期値の値をいろいろ変えて実験しよう！\n",
            "    w = np.random.randn(node_num, node_num) * 1\n",
            "    # w = np.random.randn(node_num, node_num) * 0.01\n",
            "    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
            "    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
            "\n",
            "\n",
            "    a = np.dot(x, w)\n",
            "\n",
            "\n",
            "    # 活性化関数の種類も変えて実験しよう！\n",
            "    z = sigmoid(a)\n",
            "    # z = ReLU(a)\n",
            "    # z = tanh(a)\n",
            "\n",
            "    activations[i] = z\n",
            "\n",
            "# ヒストグラムを描画\n",
            "for i, a in activations.items():\n",
            "    plt.subplot(1, len(activations), i+1)\n",
            "    plt.title(str(i+1) + \"-layer\")\n",
            "    if i != 0: plt.yticks([], [])\n",
            "    # plt.xlim(0.1, 1)\n",
            "    # plt.ylim(0, 7000)\n",
            "    plt.hist(a.flatten(), 30, range=(0,1))\n",
            "plt.show()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "om9-8N4fa8Jv",
        "outputId": "73b37521-cbe0-49a3-994a-e80ccf2a6eeb"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def ReLU(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "    \n",
        "input_data = np.random.randn(1000, 100)  # 1000個のデータ\n",
        "node_num = 100  # 各隠れ層のノード（ニューロン）の数\n",
        "hidden_layer_size = 5  # 隠れ層が5層\n",
        "activations = {}  # ここにアクティベーションの結果を格納する\n",
        "\n",
        "x = input_data\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    # 初期値の値をいろいろ変えて実験しよう！\n",
        "    w = np.random.randn(node_num, node_num) * 1\n",
        "    # w = np.random.randn(node_num, node_num) * 0.01\n",
        "    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
        "    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
        "\n",
        "\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "\n",
        "    # 活性化関数の種類も変えて実験しよう！\n",
        "    z = sigmoid(a)\n",
        "    # z = ReLU(a)\n",
        "    # z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# ヒストグラムを描画\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "    # plt.xlim(0.1, 1)\n",
        "    # plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(0,1))\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFWphNnQY3Dk",
        "outputId": "10ce8d0a-0099-4164-ed31-e818a0e537b6"
      },
      "source": [
        "cat weight_init_compare.py"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# coding: utf-8\n",
            "import os\n",
            "import sys\n",
            "\n",
            "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "from dataset.mnist import load_mnist\n",
            "from common.util import smooth_curve\n",
            "from common.multi_layer_net import MultiLayerNet\n",
            "from common.optimizer import SGD\n",
            "\n",
            "\n",
            "# 0:MNISTデータの読み込み==========\n",
            "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
            "\n",
            "train_size = x_train.shape[0]\n",
            "batch_size = 128\n",
            "max_iterations = 2000\n",
            "\n",
            "\n",
            "# 1:実験の設定==========\n",
            "weight_init_types = {'std=0.01': 0.01, 'Xavier': 'sigmoid', 'He': 'relu'}\n",
            "optimizer = SGD(lr=0.01)\n",
            "\n",
            "networks = {}\n",
            "train_loss = {}\n",
            "for key, weight_type in weight_init_types.items():\n",
            "    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
            "                                  output_size=10, weight_init_std=weight_type)\n",
            "    train_loss[key] = []\n",
            "\n",
            "\n",
            "# 2:訓練の開始==========\n",
            "for i in range(max_iterations):\n",
            "    batch_mask = np.random.choice(train_size, batch_size)\n",
            "    x_batch = x_train[batch_mask]\n",
            "    t_batch = t_train[batch_mask]\n",
            "    \n",
            "    for key in weight_init_types.keys():\n",
            "        grads = networks[key].gradient(x_batch, t_batch)\n",
            "        optimizer.update(networks[key].params, grads)\n",
            "    \n",
            "        loss = networks[key].loss(x_batch, t_batch)\n",
            "        train_loss[key].append(loss)\n",
            "    \n",
            "    if i % 100 == 0:\n",
            "        print(\"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
            "        for key in weight_init_types.keys():\n",
            "            loss = networks[key].loss(x_batch, t_batch)\n",
            "            print(key + \":\" + str(loss))\n",
            "\n",
            "\n",
            "# 3.グラフの描画==========\n",
            "markers = {'std=0.01': 'o', 'Xavier': 's', 'He': 'D'}\n",
            "x = np.arange(max_iterations)\n",
            "for key in weight_init_types.keys():\n",
            "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
            "plt.xlabel(\"iterations\")\n",
            "plt.ylabel(\"loss\")\n",
            "plt.ylim(0, 2.5)\n",
            "plt.legend()\n",
            "plt.show()"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XiW_LhZvbAfA",
        "outputId": "5bb8a66f-2acf-4dee-9ae0-b4ad706ba8ce"
      },
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.util import smooth_curve\n",
        "from common.multi_layer_net import MultiLayerNet\n",
        "from common.optimizer import SGD\n",
        "\n",
        "\n",
        "# 0:MNISTデータの読み込み==========\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 128\n",
        "max_iterations = 2000\n",
        "\n",
        "\n",
        "# 1:実験の設定==========\n",
        "weight_init_types = {'std=0.01': 0.01, 'Xavier': 'sigmoid', 'He': 'relu'}\n",
        "optimizer = SGD(lr=0.01)\n",
        "\n",
        "networks = {}\n",
        "train_loss = {}\n",
        "for key, weight_type in weight_init_types.items():\n",
        "    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
        "                                  output_size=10, weight_init_std=weight_type)\n",
        "    train_loss[key] = []\n",
        "\n",
        "\n",
        "# 2:訓練の開始==========\n",
        "for i in range(max_iterations):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    for key in weight_init_types.keys():\n",
        "        grads = networks[key].gradient(x_batch, t_batch)\n",
        "        optimizer.update(networks[key].params, grads)\n",
        "    \n",
        "        loss = networks[key].loss(x_batch, t_batch)\n",
        "        train_loss[key].append(loss)\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
        "        for key in weight_init_types.keys():\n",
        "            loss = networks[key].loss(x_batch, t_batch)\n",
        "            print(key + \":\" + str(loss))\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "markers = {'std=0.01': 'o', 'Xavier': 's', 'He': 'D'}\n",
        "x = np.arange(max_iterations)\n",
        "for key in weight_init_types.keys():\n",
        "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.ylim(0, 2.5)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========iteration:0===========\n",
            "std=0.01:2.3024350707571126\n",
            "Xavier:2.3123997669609007\n",
            "He:2.4467840583667635\n",
            "===========iteration:100===========\n",
            "std=0.01:2.3026203912671854\n",
            "Xavier:2.239383059398142\n",
            "He:1.4284343441246936\n",
            "===========iteration:200===========\n",
            "std=0.01:2.3012031166382516\n",
            "Xavier:2.115878791152764\n",
            "He:0.7391403850190368\n",
            "===========iteration:300===========\n",
            "std=0.01:2.301727881836025\n",
            "Xavier:1.71119103934294\n",
            "He:0.43710459939276536\n",
            "===========iteration:400===========\n",
            "std=0.01:2.302832073349874\n",
            "Xavier:1.0960365693001972\n",
            "He:0.35397484000263857\n",
            "===========iteration:500===========\n",
            "std=0.01:2.299046754764685\n",
            "Xavier:0.8308605641756399\n",
            "He:0.4543896906423407\n",
            "===========iteration:600===========\n",
            "std=0.01:2.2978491892028705\n",
            "Xavier:0.5851295088009166\n",
            "He:0.23661138947890056\n",
            "===========iteration:700===========\n",
            "std=0.01:2.2991489700901955\n",
            "Xavier:0.41454846212235996\n",
            "He:0.22191453459658964\n",
            "===========iteration:800===========\n",
            "std=0.01:2.3076728339460137\n",
            "Xavier:0.4404126891622984\n",
            "He:0.279265981234058\n",
            "===========iteration:900===========\n",
            "std=0.01:2.2976724758155473\n",
            "Xavier:0.4971777648510045\n",
            "He:0.36711166079512886\n",
            "===========iteration:1000===========\n",
            "std=0.01:2.3045951199353905\n",
            "Xavier:0.36353584725302246\n",
            "He:0.19593780644874814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4f5cc1c92b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_init_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0m損失関数の値\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/multi_layer_net.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}